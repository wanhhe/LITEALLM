{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c31c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af7abe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"SAVEE/data/train-00000-of-00001.parquet\"  # Replace with your path\n",
    "df = pd.read_parquet(file_path)  # Use \"pyarrow\" as the default engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28921d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['file', 'audio', 'gender', 'transcription', 'emotion', 'speaking_rate',\n",
      "       'pitch_mean', 'pitch_std', 'rms', 'relative_db'],\n",
      "      dtype='object')\n",
      "file              object\n",
      "audio             object\n",
      "gender            object\n",
      "transcription     object\n",
      "emotion           object\n",
      "speaking_rate    float32\n",
      "pitch_mean       float32\n",
      "pitch_std        float32\n",
      "rms              float32\n",
      "relative_db      float32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display all column names\n",
    "print(df.columns)\n",
    "\n",
    "# Display all column information and data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ace8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         file                                              audio gender  \\\n",
      "0  DC_a01.wav  {'bytes': b'RIFF\\x1e\\xc8\\x01\\x00WAVEfmt \\x10\\x...   male   \n",
      "1  DC_a02.wav  {'bytes': b'RIFF\\xea\\xad\\x01\\x00WAVEfmt \\x10\\x...   male   \n",
      "2  DC_a03.wav  {'bytes': b'RIFF\\x94\\x03\\x01\\x00WAVEfmt \\x10\\x...   male   \n",
      "3  DC_a04.wav  {'bytes': b'RIFF\\xd0T\\x01\\x00WAVEfmt \\x10\\x00\\...   male   \n",
      "4  DC_a05.wav  {'bytes': b'RIFF\\xe2v\\x01\\x00WAVEfmt \\x10\\x00\\...   male   \n",
      "\n",
      "                                       transcription emotion  speaking_rate  \\\n",
      "0  She had her dark suit in greasy wash water all...   anger          11.79   \n",
      "1    \"'Don't ask me to carry an oily rag like that.'   anger          12.22   \n",
      "2                              Will you tell me why?   anger           7.71   \n",
      "3      Who authorised the unlimited expense account?   anger          13.21   \n",
      "4           Destroy every file related to my audits.   anger          11.67   \n",
      "\n",
      "   pitch_mean  pitch_std       rms  relative_db  \n",
      "0  169.301239  27.078539  0.137659   -11.541980  \n",
      "1  161.700851  39.786098  0.132031   -10.949114  \n",
      "2  164.805710  25.634815  0.153754   -12.157161  \n",
      "3  169.793640  56.506123  0.156286   -17.773037  \n",
      "4  158.822891  72.264427  0.155626   -17.704559  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())       # Display first 5 rows by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b90a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['male']\n",
      "['anger' 'disgust' 'fear' 'happiness' 'neutral' 'sadness' 'surprise']\n"
     ]
    }
   ],
   "source": [
    "col = \"gender\"  # Replace with the field you are interested in\n",
    "unique_vals = df[col].dropna().unique()\n",
    "print(unique_vals)\n",
    "\n",
    "col = \"emotion\"  # Replace with the field you are interested in\n",
    "unique_vals = df[col].dropna().unique()\n",
    "print(unique_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f82484e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['bytes', 'path'])\n",
      "DC_a01.wav\n"
     ]
    }
   ],
   "source": [
    "print(df['audio'][0].keys())\n",
    "print(df['audio'][0]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baa3c28-b53d-4cff-9e52-d583493e992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"clothoaqa/train-00000-of-00085.parquet\"  # Replace with your path\n",
    "df = pd.read_parquet(file_path)  # Use \"pyarrow\" as the default engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2877a3-a12e-470c-9487-0abd555ba732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['audio', 'file_name', 'question', 'answer'], dtype='object')\n",
      "audio        object\n",
      "file_name    object\n",
      "question     object\n",
      "answer       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display all column names\n",
    "print(df.columns)\n",
    "\n",
    "# Display all column information and data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1479622d-c770-4756-852d-7e304736361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               audio  \\\n",
      "0  {'bytes': b'RIFF\\x9a\\x98#\\x00WAVEfmt \\x10\\x00\\...   \n",
      "1  {'bytes': b'RIFF\\x9a\\x98#\\x00WAVEfmt \\x10\\x00\\...   \n",
      "2  {'bytes': b'RIFF\\x9a\\x98#\\x00WAVEfmt \\x10\\x00\\...   \n",
      "3  {'bytes': b'RIFF\\x9a\\x98#\\x00WAVEfmt \\x10\\x00\\...   \n",
      "4  {'bytes': b'RIFF\\x9a\\x98#\\x00WAVEfmt \\x10\\x00\\...   \n",
      "\n",
      "                        file_name                                 question  \\\n",
      "0  AmbianceBackyard_Quiet_bip.wav  Are there more than one bird squawking?   \n",
      "1  AmbianceBackyard_Quiet_bip.wav  Are there more than one bird squawking?   \n",
      "2  AmbianceBackyard_Quiet_bip.wav  Are there more than one bird squawking?   \n",
      "3  AmbianceBackyard_Quiet_bip.wav  Are there people having a conversation?   \n",
      "4  AmbianceBackyard_Quiet_bip.wav  Are there people having a conversation?   \n",
      "\n",
      "  answer  \n",
      "0    yes  \n",
      "1    yes  \n",
      "2    yes  \n",
      "3     no  \n",
      "4     no  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())       # Display first 5 rows by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "597c79bf-f525-4e64-8b0d-c00fb1ef269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"nonspeech7k/test.parquet\"  # Replace with your path\n",
    "df = pd.read_parquet(file_path)  # Use \"pyarrow\" as the default engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886da701-19bb-4d47-a7a3-85920ed5adb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'datasetname', 'audio', 'audio_len', 'filename', 'class_id',\n",
      "       'classname', 'augmentation_id', 'augmentation_type', 'source'],\n",
      "      dtype='object')\n",
      "index                  int32\n",
      "datasetname           object\n",
      "audio                 object\n",
      "audio_len            float32\n",
      "filename              object\n",
      "class_id               int32\n",
      "classname             object\n",
      "augmentation_id        int32\n",
      "augmentation_type     object\n",
      "source                object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display all column names\n",
    "print(df.columns)\n",
    "\n",
    "# Display all column information and data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f8ac5-3893-4eb2-b50f-547abc65cb8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index  datasetname                                              audio  \\\n",
      "0      0  Nonspeech7k  {'bytes': b'RIFF$\\xe8\\x03\\x00WAVEfmt \\x10\\x00\\...   \n",
      "1      1  Nonspeech7k  {'bytes': b'RIFF\\xa4\\xdb\\x03\\x00WAVEfmt \\x10\\x...   \n",
      "2      2  Nonspeech7k  {'bytes': b'RIFF\\xa4\\xd1\\x03\\x00WAVEfmt \\x10\\x...   \n",
      "3      3  Nonspeech7k  {'bytes': b'RIFFd5\\x02\\x00WAVEfmt \\x10\\x00\\x00...   \n",
      "4      4  Nonspeech7k  {'bytes': b'RIFF\\xa4\\xae\\x03\\x00WAVEfmt \\x10\\x...   \n",
      "\n",
      "   audio_len          filename  class_id classname  augmentation_id  \\\n",
      "0      4.000  112557-2_0_0.wav         0    breath                0   \n",
      "1      3.950  112557-3_0_0.wav         0    breath                0   \n",
      "2      3.910  112557-4_0_0.wav         0    breath                0   \n",
      "3      2.261    140301_0_0.wav         0    breath                0   \n",
      "4      3.770  144128-1_0_0.wav         0    breath                0   \n",
      "\n",
      "  augmentation_type                  source  \n",
      "0          Original  https://freesound.org/  \n",
      "1          Original  https://freesound.org/  \n",
      "2          Original  https://freesound.org/  \n",
      "3          Original  https://freesound.org/  \n",
      "4          Original  https://freesound.org/  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())       # Display first 5 rows by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d9949a-b3f1-41b8-9dff-5b4c32d8aa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['breath' 'cough' 'crying' 'laugh' 'screaming' 'sneeze' 'yawm']\n"
     ]
    }
   ],
   "source": [
    "col = \"classname\"  # Replace with the field you are interested in\n",
    "unique_vals = df[col].dropna().unique()\n",
    "print(unique_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53399636-6a1b-4b0b-bb85-fedc1ed8c4f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"mmau/test_mini-00004-of-00008.parquet\"  # Replace with your path\n",
    "df = pd.read_parquet(file_path)  # Use \"pyarrow\" as the default engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdeb3e8-af67-4fdb-8334-a4f2968abf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'audio', 'question', 'choices', 'answer', 'dataset', 'task',\n",
      "       'split', 'category', 'sub-category', 'difficulty'],\n",
      "      dtype='object')\n",
      "id              object\n",
      "audio           object\n",
      "question        object\n",
      "choices         object\n",
      "answer          object\n",
      "dataset         object\n",
      "task            object\n",
      "split           object\n",
      "category        object\n",
      "sub-category    object\n",
      "difficulty      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Display all column names\n",
    "print(df.columns)\n",
    "\n",
    "# Display all column information and data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee066ce-8139-4c71-980a-0ec26215e75b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     id  \\\n",
      "0  de1f4cc4-3d6a-4055-861c-792c116aee6f   \n",
      "1  f18fa592-6f36-45d8-a328-1cc30a819771   \n",
      "2  eb1f6c4f-781e-415d-8ff4-ff4743256918   \n",
      "3  11ec294d-ca0d-4e6b-9c67-8250c87057c4   \n",
      "4  e2363fed-cfd8-4dc0-98f2-aa5cd2ac973e   \n",
      "\n",
      "                                               audio  \\\n",
      "0  {'bytes': b'RIFF\\x12\\xc0P\\x00WAVEfmt \\x12\\x00\\...   \n",
      "1  {'bytes': b'RIFF$\\xe2\\x04\\x00WAVEfmt \\x10\\x00\\...   \n",
      "2  {'bytes': b'RIFF\\xa4\\x99@\\x00WAVEfmt \\x10\\x00\\...   \n",
      "3  {'bytes': b'RIFF$\\xe2\\x04\\x00WAVEfmt \\x10\\x00\\...   \n",
      "4  {'bytes': b'RIFF\\x12\\xc0P\\x00WAVEfmt \\x12\\x00\\...   \n",
      "\n",
      "                                            question  \\\n",
      "0  What is the duration of the chord G#:sus2/1 in...   \n",
      "1  What instruments accompany the female voice in...   \n",
      "2       According to the audio, where are we moving?   \n",
      "3       Which instruments can be heard in the audio?   \n",
      "4  What chord is played from 5.65 to 8.47 in the ...   \n",
      "\n",
      "                                             choices  \\\n",
      "0  [\"2.82 seconds\", \"2.83 seconds\", \"3.83 seconds...   \n",
      "1  [\"Piano and drums\", \"Guitar and bass\", \"Flute ...   \n",
      "2  [\"To the moon\", \"Where the sun will always shi...   \n",
      "3  [\"Piano and violin\", \"Electric guitar and acou...   \n",
      "4  [\"A#:min/1\", \"D#:7/5\", \"G#:maj/1\", \"C#:maj(#9)...   \n",
      "\n",
      "                               answer     dataset   task      split  \\\n",
      "0                        2.82 seconds   guitarset  music  test-mini   \n",
      "1                   Flute and strings  musicbench  music  test-mini   \n",
      "2     Where the sun will always shine      musidb  music  test-mini   \n",
      "3  Electric guitar and acoustic drums  musicbench  music  test-mini   \n",
      "4                            G#:maj/1   guitarset  music  test-mini   \n",
      "\n",
      "                 category        sub-category difficulty  \n",
      "0               Reasoning  Temporal Reasoning     medium  \n",
      "1  Information Extraction     Instrumentation       easy  \n",
      "2               Reasoning   Lyrical Reasoning     medium  \n",
      "3  Information Extraction     Instrumentation       easy  \n",
      "4               Reasoning  Temporal Reasoning     medium  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())       # Display first 5 rows by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35af0548-b38d-4932-bcc8-47fedea2cca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['music']\n"
     ]
    }
   ],
   "source": [
    "col = \"task\"  # Replace with the field you are interested in\n",
    "unique_vals = df[col].dropna().unique()\n",
    "print(unique_vals)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
